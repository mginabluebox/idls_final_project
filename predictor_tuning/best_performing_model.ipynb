{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from node2vec_impl_dp import Node2Vec\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = 'results/'\n",
    "DATA_PATH = '../data/'\n",
    "NUM_GPUS = 1\n",
    "NUM_GPUS_STR = str(NUM_GPUS)\n",
    "TYPE = 'v100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters from tuning experiments\n",
    "P = 1\n",
    "Q = 1\n",
    "WALK = 50\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.0025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index map\n",
    "with open(f'{DATA_PATH}reddit_index.json') as f:\n",
    "    reddit_dict = json.load(f)\n",
    "\n",
    "# read reddit s2d as a Data object in pytorch geometric\n",
    "## read the entire dataset in memory as a pandas dataframe\n",
    "df = pd.read_csv(f'{DATA_PATH}reddit_subreddit_to_domain__gt-01-urls.csv', header=None)\n",
    "\n",
    "## extract source and target nodes and map to corresponding integer indices\n",
    "source_nodes = df.iloc[:,0].apply(lambda x: reddit_dict[x]).values.tolist()\n",
    "target_nodes = df.iloc[:,1].apply(lambda x: reddit_dict[x]).values.tolist()\n",
    "num_nodes = len(set(source_nodes).union(set(target_nodes)))\n",
    "weight = df.iloc[:,2].values.tolist()\n",
    "\n",
    "## convert to pytorch geometric Data object\n",
    "edge_index = torch.tensor([source_nodes, target_nodes])\n",
    "edge_attr = torch.tensor(weight)[:,None]\n",
    "data = Data(edge_index=edge_index, edge_attr=edge_attr)\n",
    "data.num_nodes = num_nodes\n",
    "transform = T.ToUndirected()\n",
    "data = transform(data)\n",
    "\n",
    "# read domain ideology for evaluation\n",
    "domain_ideology = pd.read_csv(f'{DATA_PATH}robertson_et_al.csv')\n",
    "domain_ideology = domain_ideology[['domain', 'score']].copy()\n",
    "domain_ideology['id'] = domain_ideology['domain'].apply(lambda x: reddit_dict[x] if x in reddit_dict else None)\n",
    "domain_ideology = domain_ideology[domain_ideology['id'].notna()].reset_index(drop=True)\n",
    "domain_ideology['id'] = domain_ideology['id'].astype('int64')\n",
    "\n",
    "# train, test, val split\n",
    "train = domain_ideology.sample(frac=0.8,random_state=42)\n",
    "test = domain_ideology[~domain_ideology.index.isin(train.index)]\n",
    "train_sub = train.sample(frac=0.8, random_state=24)\n",
    "val = train[~train.index.isin(train_sub.index)]\n",
    "\n",
    "train_x, train_y = train_sub['id'].tolist(), train_sub['score'].tolist()\n",
    "val_x, val_y = val['id'].tolist(), val['score'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 3.5461, Train MSE: 0.1857, Val MSE: 0.1856, Total Time: 2.46 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 02, Loss: 1.3729, Train MSE: 0.1858, Val MSE: 0.1841, Total Time: 4.93 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 03, Loss: 0.9798, Train MSE: 0.1865, Val MSE: 0.1835, Total Time: 7.39 mins, Train time: 2.45 mins, Val Time: 0.00 mins\n",
      "Epoch: 04, Loss: 0.8827, Train MSE: 0.1864, Val MSE: 0.1843, Total Time: 9.85 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 05, Loss: 0.8560, Train MSE: 0.1859, Val MSE: 0.1834, Total Time: 12.31 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 06, Loss: 0.8447, Train MSE: 0.1839, Val MSE: 0.1813, Total Time: 14.78 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 07, Loss: 0.8383, Train MSE: 0.1822, Val MSE: 0.1798, Total Time: 17.24 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 08, Loss: 0.8342, Train MSE: 0.1736, Val MSE: 0.1734, Total Time: 19.70 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 09, Loss: 0.8310, Train MSE: 0.1623, Val MSE: 0.1638, Total Time: 22.17 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 10, Loss: 0.8285, Train MSE: 0.1509, Val MSE: 0.1508, Total Time: 24.68 mins, Train time: 2.51 mins, Val Time: 0.00 mins\n",
      "Epoch: 11, Loss: 0.8268, Train MSE: 0.1423, Val MSE: 0.1439, Total Time: 27.21 mins, Train time: 2.53 mins, Val Time: 0.00 mins\n",
      "Epoch: 12, Loss: 0.8254, Train MSE: 0.1362, Val MSE: 0.1386, Total Time: 29.73 mins, Train time: 2.52 mins, Val Time: 0.00 mins\n",
      "Epoch: 13, Loss: 0.8244, Train MSE: 0.1328, Val MSE: 0.1361, Total Time: 32.24 mins, Train time: 2.51 mins, Val Time: 0.00 mins\n",
      "Epoch: 14, Loss: 0.8236, Train MSE: 0.1307, Val MSE: 0.1307, Total Time: 34.72 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 15, Loss: 0.8229, Train MSE: 0.1311, Val MSE: 0.1313, Total Time: 37.19 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 16, Loss: 0.8224, Train MSE: 0.1298, Val MSE: 0.1270, Total Time: 39.66 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 17, Loss: 0.8219, Train MSE: 0.1315, Val MSE: 0.1286, Total Time: 42.11 mins, Train time: 2.45 mins, Val Time: 0.00 mins\n",
      "Epoch: 18, Loss: 0.8215, Train MSE: 0.1295, Val MSE: 0.1254, Total Time: 44.59 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 19, Loss: 0.8212, Train MSE: 0.1281, Val MSE: 0.1260, Total Time: 47.04 mins, Train time: 2.45 mins, Val Time: 0.00 mins\n",
      "Epoch: 20, Loss: 0.8210, Train MSE: 0.1279, Val MSE: 0.1286, Total Time: 49.51 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 21, Loss: 0.8207, Train MSE: 0.1266, Val MSE: 0.1281, Total Time: 51.98 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 22, Loss: 0.8205, Train MSE: 0.1280, Val MSE: 0.1293, Total Time: 54.45 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 23, Loss: 0.8204, Train MSE: 0.1271, Val MSE: 0.1272, Total Time: 56.92 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 24, Loss: 0.8202, Train MSE: 0.1273, Val MSE: 0.1250, Total Time: 59.38 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 25, Loss: 0.8201, Train MSE: 0.1262, Val MSE: 0.1264, Total Time: 61.85 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 26, Loss: 0.8199, Train MSE: 0.1253, Val MSE: 0.1297, Total Time: 64.34 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 27, Loss: 0.8198, Train MSE: 0.1262, Val MSE: 0.1266, Total Time: 66.80 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 28, Loss: 0.8196, Train MSE: 0.1251, Val MSE: 0.1276, Total Time: 69.29 mins, Train time: 2.49 mins, Val Time: 0.00 mins\n",
      "Epoch: 29, Loss: 0.8195, Train MSE: 0.1244, Val MSE: 0.1280, Total Time: 71.74 mins, Train time: 2.45 mins, Val Time: 0.00 mins\n",
      "Epoch: 30, Loss: 0.8195, Train MSE: 0.1256, Val MSE: 0.1270, Total Time: 74.22 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 31, Loss: 0.8194, Train MSE: 0.1260, Val MSE: 0.1252, Total Time: 76.69 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 32, Loss: 0.8193, Train MSE: 0.1241, Val MSE: 0.1244, Total Time: 79.17 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 33, Loss: 0.8192, Train MSE: 0.1230, Val MSE: 0.1238, Total Time: 81.64 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 34, Loss: 0.8191, Train MSE: 0.1258, Val MSE: 0.1290, Total Time: 84.09 mins, Train time: 2.45 mins, Val Time: 0.00 mins\n",
      "Epoch: 35, Loss: 0.8191, Train MSE: 0.1244, Val MSE: 0.1278, Total Time: 86.56 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 36, Loss: 0.8189, Train MSE: 0.1244, Val MSE: 0.1267, Total Time: 89.04 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 37, Loss: 0.8188, Train MSE: 0.1239, Val MSE: 0.1249, Total Time: 91.51 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 38, Loss: 0.8188, Train MSE: 0.1242, Val MSE: 0.1258, Total Time: 93.97 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 39, Loss: 0.8188, Train MSE: 0.1240, Val MSE: 0.1285, Total Time: 96.43 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 40, Loss: 0.8187, Train MSE: 0.1243, Val MSE: 0.1240, Total Time: 98.90 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 41, Loss: 0.8187, Train MSE: 0.1241, Val MSE: 0.1224, Total Time: 101.38 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 42, Loss: 0.8187, Train MSE: 0.1228, Val MSE: 0.1260, Total Time: 103.90 mins, Train time: 2.52 mins, Val Time: 0.00 mins\n",
      "Epoch: 43, Loss: 0.8185, Train MSE: 0.1248, Val MSE: 0.1262, Total Time: 106.35 mins, Train time: 2.45 mins, Val Time: 0.00 mins\n",
      "Epoch: 44, Loss: 0.8185, Train MSE: 0.1225, Val MSE: 0.1259, Total Time: 108.82 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 45, Loss: 0.8185, Train MSE: 0.1225, Val MSE: 0.1227, Total Time: 111.28 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 46, Loss: 0.8185, Train MSE: 0.1228, Val MSE: 0.1253, Total Time: 113.76 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 47, Loss: 0.8184, Train MSE: 0.1230, Val MSE: 0.1229, Total Time: 116.29 mins, Train time: 2.53 mins, Val Time: 0.00 mins\n",
      "Epoch: 48, Loss: 0.8183, Train MSE: 0.1226, Val MSE: 0.1240, Total Time: 118.81 mins, Train time: 2.52 mins, Val Time: 0.00 mins\n",
      "Epoch: 49, Loss: 0.8183, Train MSE: 0.1232, Val MSE: 0.1268, Total Time: 121.29 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 50, Loss: 0.8183, Train MSE: 0.1233, Val MSE: 0.1288, Total Time: 123.77 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 51, Loss: 0.8182, Train MSE: 0.1238, Val MSE: 0.1285, Total Time: 126.24 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 52, Loss: 0.8182, Train MSE: 0.1239, Val MSE: 0.1297, Total Time: 128.71 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 53, Loss: 0.8182, Train MSE: 0.1233, Val MSE: 0.1272, Total Time: 131.17 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 54, Loss: 0.8182, Train MSE: 0.1238, Val MSE: 0.1225, Total Time: 133.68 mins, Train time: 2.51 mins, Val Time: 0.00 mins\n",
      "Epoch: 55, Loss: 0.8182, Train MSE: 0.1248, Val MSE: 0.1207, Total Time: 136.20 mins, Train time: 2.52 mins, Val Time: 0.00 mins\n",
      "Epoch: 56, Loss: 0.8182, Train MSE: 0.1242, Val MSE: 0.1261, Total Time: 138.67 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 57, Loss: 0.8182, Train MSE: 0.1234, Val MSE: 0.1264, Total Time: 141.15 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 58, Loss: 0.8181, Train MSE: 0.1242, Val MSE: 0.1239, Total Time: 143.63 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 59, Loss: 0.8181, Train MSE: 0.1240, Val MSE: 0.1277, Total Time: 146.09 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 60, Loss: 0.8181, Train MSE: 0.1248, Val MSE: 0.1293, Total Time: 148.55 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 61, Loss: 0.8181, Train MSE: 0.1234, Val MSE: 0.1238, Total Time: 151.03 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 62, Loss: 0.8181, Train MSE: 0.1237, Val MSE: 0.1252, Total Time: 153.50 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 63, Loss: 0.8181, Train MSE: 0.1223, Val MSE: 0.1281, Total Time: 155.96 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 64, Loss: 0.8181, Train MSE: 0.1234, Val MSE: 0.1276, Total Time: 158.41 mins, Train time: 2.45 mins, Val Time: 0.00 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65, Loss: 0.8181, Train MSE: 0.1225, Val MSE: 0.1260, Total Time: 160.89 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 66, Loss: 0.8181, Train MSE: 0.1228, Val MSE: 0.1274, Total Time: 163.37 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 67, Loss: 0.8180, Train MSE: 0.1228, Val MSE: 0.1238, Total Time: 165.84 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 68, Loss: 0.8181, Train MSE: 0.1227, Val MSE: 0.1198, Total Time: 168.29 mins, Train time: 2.45 mins, Val Time: 0.00 mins\n",
      "Epoch: 69, Loss: 0.8181, Train MSE: 0.1226, Val MSE: 0.1203, Total Time: 170.76 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 70, Loss: 0.8180, Train MSE: 0.1244, Val MSE: 0.1222, Total Time: 173.23 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 71, Loss: 0.8181, Train MSE: 0.1246, Val MSE: 0.1235, Total Time: 175.70 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 72, Loss: 0.8180, Train MSE: 0.1241, Val MSE: 0.1247, Total Time: 178.17 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 73, Loss: 0.8181, Train MSE: 0.1231, Val MSE: 0.1258, Total Time: 180.63 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 74, Loss: 0.8180, Train MSE: 0.1237, Val MSE: 0.1246, Total Time: 183.09 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 75, Loss: 0.8181, Train MSE: 0.1236, Val MSE: 0.1221, Total Time: 185.59 mins, Train time: 2.50 mins, Val Time: 0.00 mins\n",
      "Epoch: 76, Loss: 0.8180, Train MSE: 0.1229, Val MSE: 0.1246, Total Time: 188.05 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 77, Loss: 0.8180, Train MSE: 0.1237, Val MSE: 0.1229, Total Time: 190.52 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 78, Loss: 0.8180, Train MSE: 0.1232, Val MSE: 0.1241, Total Time: 192.99 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 79, Loss: 0.8180, Train MSE: 0.1224, Val MSE: 0.1221, Total Time: 195.45 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 80, Loss: 0.8180, Train MSE: 0.1228, Val MSE: 0.1252, Total Time: 197.93 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 81, Loss: 0.8180, Train MSE: 0.1215, Val MSE: 0.1301, Total Time: 200.42 mins, Train time: 2.49 mins, Val Time: 0.00 mins\n",
      "Epoch: 82, Loss: 0.8180, Train MSE: 0.1228, Val MSE: 0.1284, Total Time: 202.90 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 83, Loss: 0.8180, Train MSE: 0.1235, Val MSE: 0.1286, Total Time: 205.38 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 84, Loss: 0.8180, Train MSE: 0.1245, Val MSE: 0.1266, Total Time: 207.87 mins, Train time: 2.49 mins, Val Time: 0.00 mins\n",
      "Epoch: 85, Loss: 0.8180, Train MSE: 0.1240, Val MSE: 0.1251, Total Time: 210.30 mins, Train time: 2.43 mins, Val Time: 0.00 mins\n",
      "Epoch: 86, Loss: 0.8180, Train MSE: 0.1239, Val MSE: 0.1222, Total Time: 212.78 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 87, Loss: 0.8180, Train MSE: 0.1240, Val MSE: 0.1260, Total Time: 215.26 mins, Train time: 2.49 mins, Val Time: 0.00 mins\n",
      "Epoch: 88, Loss: 0.8180, Train MSE: 0.1227, Val MSE: 0.1277, Total Time: 217.76 mins, Train time: 2.49 mins, Val Time: 0.00 mins\n",
      "Epoch: 89, Loss: 0.8181, Train MSE: 0.1241, Val MSE: 0.1261, Total Time: 220.23 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 90, Loss: 0.8180, Train MSE: 0.1235, Val MSE: 0.1236, Total Time: 222.69 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 91, Loss: 0.8180, Train MSE: 0.1238, Val MSE: 0.1231, Total Time: 225.17 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 92, Loss: 0.8180, Train MSE: 0.1237, Val MSE: 0.1227, Total Time: 227.66 mins, Train time: 2.49 mins, Val Time: 0.00 mins\n",
      "Epoch: 93, Loss: 0.8180, Train MSE: 0.1233, Val MSE: 0.1236, Total Time: 230.13 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 94, Loss: 0.8181, Train MSE: 0.1240, Val MSE: 0.1229, Total Time: 232.60 mins, Train time: 2.47 mins, Val Time: 0.00 mins\n",
      "Epoch: 95, Loss: 0.8180, Train MSE: 0.1235, Val MSE: 0.1250, Total Time: 235.06 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 96, Loss: 0.8180, Train MSE: 0.1239, Val MSE: 0.1232, Total Time: 237.54 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 97, Loss: 0.8180, Train MSE: 0.1232, Val MSE: 0.1249, Total Time: 240.01 mins, Train time: 2.46 mins, Val Time: 0.00 mins\n",
      "Epoch: 98, Loss: 0.8180, Train MSE: 0.1229, Val MSE: 0.1270, Total Time: 242.49 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n",
      "Epoch: 99, Loss: 0.8180, Train MSE: 0.1231, Val MSE: 0.1264, Total Time: 244.97 mins, Train time: 2.48 mins, Val Time: 0.00 mins\n"
     ]
    }
   ],
   "source": [
    "# model and optimizer specification \n",
    "model = Node2Vec(data.edge_index, embedding_dim=128, \n",
    "              walk_length=WALK, context_size=10, walks_per_node=10, \n",
    "              num_negative_samples=1, p=P, q=Q, sparse=True)\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.to(device)\n",
    "loader = model.module.loader(batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=LR)\n",
    "\n",
    "def train():\n",
    "    \"\"\"\n",
    "    Train node2vec batch by batch using postive and negative samples from loader.\n",
    "    Returns training loss (log-likelihood).\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # concatenate along last dimension\n",
    "        batch = torch.cat((pos_rw, neg_rw), -1)\n",
    "\n",
    "        # for calling data parallel, call model.forward\n",
    "        # for calling forward without dataparallel, call model.module\n",
    "        loss = model(batch.to(device))\n",
    "        loss = loss.sum()/NUM_GPUS\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    \"\"\"\n",
    "    Evaluate embedding on downstream ideology scoring task using default predictor (Ridge).\n",
    "    Returns train and validation MSE.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    z = model.module()\n",
    "\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    clf = Ridge(alpha=0.01).fit(z[train_x].detach().cpu().numpy(), train_y)\n",
    "    train_mse = mean_squared_error(train_y, clf.predict(z[train_x].detach().cpu().numpy()))\n",
    "\n",
    "    preds = clf.predict(z[val_x].detach().cpu().numpy())\n",
    "    val_mse = mean_squared_error(val_y, preds)\n",
    "\n",
    "    return train_mse, val_mse\n",
    "\n",
    "with open(f'results/jupyter_{TYPE}_{NUM_GPUS_STR}_log.txt', 'a') as f:\n",
    "    f.write(f'Loss,Train MSE,Val MSE,Total Time,Train Time,Val Time\\n')\n",
    "    \n",
    "best_val_mse = 0.0\n",
    "for epoch in range(1, NUM_EPOCHS):\n",
    "    # train\n",
    "    loss = train()\n",
    "\n",
    "    # validation\n",
    "    train_mse, val_mse = test()\n",
    "\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train MSE: {train_mse:.4f}, Val MSE: {val_mse:.4f}, Total Time: {(end_time-start_time)/60:.2f} mins, Train time: {train_time/60:.2f} mins, Val Time: {val_time/60:.2f} mins')\n",
    "    \n",
    "    with open(f'{SAVE_PATH}jupyter_{TYPE}_{NUM_GPUS_STR}_log.txt', 'a') as f:\n",
    "        f.write(f'{str(loss)},{str(train_mse)},{str(val_mse)},{str(end_time-start_time)},{str(train_time)},{str(val_time)}\\n')\n",
    "        \n",
    "    # checkpoint\n",
    "    if val_mse <= best_val_mse:\n",
    "        torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        'val_mse': val_mse,\n",
    "        }, str(epoch)+\".pth\")\n",
    "        best_val_mse = val_mse\n",
    "\n",
    "# save model\n",
    "torch.save(model.state_dict(), f'{SAVE_PATH}jupyter_{TYPE}_{NUM_GPUS}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
